{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0f6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_names.dataset_names import DatasetNames\n",
    "from attacks.attack_names import AttackNames\n",
    "from detections.detection_names import DetectionNames\n",
    "from evaluation.utils import get_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d1bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from statistics import fmean\n",
    "\n",
    "def get_metrics(base_path):\n",
    "    TP_list = []\n",
    "    FP_list = []\n",
    "    FN_list = []\n",
    "    Precision_list = []\n",
    "    Recall_list = []\n",
    "    malicious_clients_list = []\n",
    "    detected_clients_list = []\n",
    "    effectivenesses_list = []\n",
    "    time_per_iteration_list = []\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        relative_path = os.path.relpath(root, base_path)\n",
    "        path_parts = relative_path.split(os.sep)\n",
    "\n",
    "        # We expect 2 parts: date, time\n",
    "        if len(path_parts) >= 2:\n",
    "            for file_name in files:\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                if \"Precision_Recall\" in file_name:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        precision_recall = json.load(f)\n",
    "                    TP_list.append(precision_recall[\"TP\"])\n",
    "                    FP_list.append(precision_recall[\"FP\"])\n",
    "                    FN_list.append(precision_recall[\"FN\"])\n",
    "                    Precision_list.append(precision_recall[\"Precision\"])\n",
    "                    Recall_list.append(precision_recall[\"Recall\"])\n",
    "                elif \"clients\" in file_name:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        clients = json.load(f)\n",
    "                    num_clients = clients[\"num_clients\"]\n",
    "                    malicious_clients = clients[\"malicious_clients\"]\n",
    "                    malicious_clients_list.append(malicious_clients)\n",
    "                    detected_clients_list.append(clients[\"detected_clients\"])\n",
    "                elif \"round_metrics\" in file_name:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        round_metrics = json.load(f)\n",
    "                elif \"time\" in file_name:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        time = json.load(f)\n",
    "                    time_per_iteration = time[\"time_per_iteration\"]\n",
    "                    time_per_iteration_list.append(time_per_iteration)\n",
    "\n",
    "\n",
    "            # Calculate the Effectiveness of the run\n",
    "            acc_0 = round_metrics[0][\"accuracy\"]    # We use the accuracy of the first (0) round.\n",
    "            acc_n = round_metrics[-1][\"accuracy\"]\n",
    "            clients_done = []\n",
    "            effectivenesses = []\n",
    "            for idx, round_metric in enumerate(round_metrics):\n",
    "                detected_FRs = round_metric[\"detected_FR\"]\n",
    "                acc_i_1 = round_metrics[idx-1][\"accuracy\"]  # Get the accuracy of the previous global model.\n",
    "                if detected_FRs:\n",
    "                    for det_FR in detected_FRs:\n",
    "                        # Check whether the FR is malicious and if it has not already been detected in a previous round\n",
    "                        if det_FR in malicious_clients and det_FR not in clients_done:\n",
    "                            # In this round, a new FR was detected.\n",
    "                            # Calculate the Effectiveness for this FR.\n",
    "                            effectiveness = (1 - (acc_i_1/acc_n)) / (1 - (acc_0/acc_n))\n",
    "                            effectivenesses.append(effectiveness)\n",
    "                            clients_done.append(det_FR)\n",
    "            \n",
    "            not_detected_FR = [cid for cid in malicious_clients if cid not in clients_done]\n",
    "            for n_d_FR in not_detected_FR:\n",
    "                effectivenesses.append(0.0)\n",
    "            effectiveness_all = fmean(effectivenesses)\n",
    "\n",
    "            effectivenesses_list.append(effectiveness_all)\n",
    "\n",
    "    TP_avg = fmean(TP_list)\n",
    "    FP_avg = fmean(FP_list)\n",
    "    FN_avg = fmean(FN_list)\n",
    "    Precision_avg = fmean(Precision_list)\n",
    "    Recalls_avg = fmean(Recall_list)\n",
    "    effectiveness_avg = fmean(effectivenesses_list)\n",
    "    time_per_iteration_avg = fmean(time_per_iteration_list)\n",
    "\n",
    "    return {\n",
    "        \"TP_avg\": TP_avg,\n",
    "        \"FP_avg\": FP_avg,\n",
    "        \"FN_avg\": FN_avg,\n",
    "        \"Precision_avg\": Precision_avg,\n",
    "        \"Recall_avg\": Recalls_avg,\n",
    "        \"Effectiveness_avg\": effectiveness_avg,\n",
    "        \"time_per_iteration_avg\": time_per_iteration_avg\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b30042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP_avg': 10.0, 'FP_avg': 3.0, 'FN_avg': 0.0, 'Precision_avg': 0.7692307692307693, 'Recall_avg': 1.0, 'Effectiveness_avg': 0.4200041315631395, 'time_per_iteration_avg': 3.05485565662384}\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetNames.mnist\n",
    "n_clients = 100\n",
    "perc_malicious = 10\n",
    "attack = AttackNames.random_weights_attack\n",
    "detection = DetectionNames.fgfl_detection\n",
    "\n",
    "test_path = \"./outputs/\" + get_output_path(dataset, n_clients, perc_malicious, attack, detection)\n",
    "metrics = get_metrics(test_path)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167de65d",
   "metadata": {},
   "source": [
    "# MNIST experiment evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02eea377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def get_experiment_results(dataset: DatasetNames, n_clients: List, perc_malicious: List, attacks: List, detections: List):\n",
    "    results = {}\n",
    "\n",
    "    for n_c in n_clients:\n",
    "        for perc_m in perc_malicious:\n",
    "            for attack in attacks:\n",
    "                for detection in detections:\n",
    "                    path_name = get_output_path(dataset, n_c, perc_m, attack, detection)\n",
    "                    path = \"./outputs/\" + path_name\n",
    "                    metrics = get_metrics(path)\n",
    "                    results[path_name] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e82607a",
   "metadata": {},
   "source": [
    "## Baseline Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855ead4",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5369d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetNames.mnist\n",
    "n_clients = [10, 100]\n",
    "perc_malicious = [0]\n",
    "attacks = [AttackNames.no_attack]\n",
    "detections = [DetectionNames.no_detection]\n",
    "\n",
    "results = get_experiment_results(dataset, n_clients, perc_malicious, attacks, detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e97d05",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetNames.cifar10\n",
    "n_clients = [10, 100]\n",
    "perc_malicious = [0]\n",
    "attacks = [AttackNames.no_attack]\n",
    "detections = [DetectionNames.no_detection]\n",
    "\n",
    "results = get_experiment_results(dataset, n_clients, perc_malicious, attacks, detections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
