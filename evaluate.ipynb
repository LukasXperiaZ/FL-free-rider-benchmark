{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0f6860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./outputs/mnist--n=10--10%--random_weights--delta_dagmm\n"
     ]
    }
   ],
   "source": [
    "from dataset_names.dataset_names import DatasetNames\n",
    "from attacks.attack_names import AttackNames\n",
    "from detections.detection_names import DetectionNames\n",
    "from evaluation.utils import get_output_path\n",
    "\n",
    "dataset = DatasetNames.mnist\n",
    "n_clients = 10\n",
    "perc_malicious = 10\n",
    "attack = AttackNames.random_weights_attack\n",
    "detection = DetectionNames.delta_dagmm_detection\n",
    "\n",
    "test_path = \"./outputs/\" + get_output_path(dataset, n_clients, perc_malicious, attack, detection)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2d1bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from statistics import fmean\n",
    "\n",
    "def get_avg_effectiveness(base_path):\n",
    "    TP_list = []\n",
    "    FP_list = []\n",
    "    FN_list = []\n",
    "    Precision_list = []\n",
    "    Recall_list = []\n",
    "    malicious_clients_list = []\n",
    "    detected_clients_list = []\n",
    "    effectivenesses_list = []\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        relative_path = os.path.relpath(root, base_path)\n",
    "        path_parts = relative_path.split(os.sep)\n",
    "\n",
    "        # We expect 2 parts: date, time\n",
    "        if len(path_parts) >= 2:\n",
    "            for file_name in files:\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                if \"Precision_Recall\" in file_name:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        precision_recall = json.load(f)\n",
    "                    TP_list.append(precision_recall[\"TP\"])\n",
    "                    FP_list.append(precision_recall[\"FP\"])\n",
    "                    FN_list.append(precision_recall[\"FN\"])\n",
    "                    Precision_list.append(precision_recall[\"Precision\"])\n",
    "                    Recall_list.append(precision_recall[\"Recall\"])\n",
    "                elif \"clients\" in file_name:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        clients = json.load(f)\n",
    "                    num_clients = clients[\"num_clients\"]\n",
    "                    malicious_clients = clients[\"malicious_clients\"]\n",
    "                    malicious_clients_list.append(malicious_clients)\n",
    "                    detected_clients_list.append(clients[\"detected_clients\"])\n",
    "                elif \"round_metrics\" in file_name:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        round_metrics = json.load(f)\n",
    "\n",
    "\n",
    "            # Calculate the Effectiveness of the run\n",
    "            acc_0 = round_metrics[0][\"accuracy\"]    # We use the accuracy of the first (0) round.\n",
    "            acc_n = round_metrics[-1][\"accuracy\"]\n",
    "            clients_done = []\n",
    "            effectivenesses = []\n",
    "            for idx, round_metric in enumerate(round_metrics):\n",
    "                detected_FRs = round_metric[\"detected_FR\"]\n",
    "                acc_i_1 = round_metrics[idx-1][\"accuracy\"]  # Get the accuracy of the previous global model.\n",
    "                if detected_FRs:\n",
    "                    for det_FR in detected_FRs:\n",
    "                        # Check whether the FR is malicious and if it has not already been detected in a previous round\n",
    "                        if det_FR in malicious_clients and det_FR not in clients_done:\n",
    "                            # In this round, a new FR was detected.\n",
    "                            # Calculate the Effectiveness for this FR.\n",
    "                            effectiveness = (1 - (acc_i_1/acc_n)) / (1 - (acc_0/acc_n))\n",
    "                            effectivenesses.append(effectiveness)\n",
    "                            clients_done.append(det_FR)\n",
    "            \n",
    "            not_detected_FR = [cid for cid in malicious_clients if cid not in clients_done]\n",
    "            for n_d_FR in not_detected_FR:\n",
    "                effectivenesses.append(0.0)\n",
    "            effectiveness_all = fmean(effectivenesses)\n",
    "\n",
    "            effectivenesses_list.append(effectiveness_all)\n",
    "\n",
    "    TP_avg = fmean(TP_list)\n",
    "    FP_avg = fmean(FP_list)\n",
    "    FN_avg = fmean(FN_list)\n",
    "    Precision_avg = fmean(Precision_list)\n",
    "    Recalls_avg = fmean(Recall_list)\n",
    "    effectiveness_avg = fmean(effectivenesses_list)\n",
    "\n",
    "    return {\n",
    "        \"TP_avg\": TP_avg,\n",
    "        \"FP_avg\": FP_avg,\n",
    "        \"FN_avg\": FN_avg,\n",
    "        \"Precision_avg\": Precision_avg,\n",
    "        \"Recalls_avg\": Recalls_avg,\n",
    "        \"Effectiveness_avg\": effectiveness_avg\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcbb2d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07291666666666659]\n",
      "[0.07837713231904093]\n",
      "[0.08438330828805912]\n",
      "{'TP_avg': 1.0, 'FP_avg': 0.3333333333333333, 'FN_avg': 0.0, 'Precision_avg': 0.8333333333333334, 'Recalls_avg': 1.0, 'Effectiveness_avg': 0.07855903575792221}\n"
     ]
    }
   ],
   "source": [
    "effectiveness = get_avg_effectiveness(test_path)\n",
    "print(effectiveness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9b30042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP_avg': 10.0, 'FP_avg': 3.0, 'FN_avg': 0.0, 'Precision_avg': 0.7692307692307693, 'Recalls_avg': 1.0, 'Effectiveness_avg': 0.4200041315631395}\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetNames.mnist\n",
    "n_clients = 100\n",
    "perc_malicious = 10\n",
    "attack = AttackNames.random_weights_attack\n",
    "detection = DetectionNames.fgfl_detection\n",
    "\n",
    "test_path = \"./outputs/\" + get_output_path(dataset, n_clients, perc_malicious, attack, detection)\n",
    "effectiveness = get_avg_effectiveness(test_path)\n",
    "print(effectiveness)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
