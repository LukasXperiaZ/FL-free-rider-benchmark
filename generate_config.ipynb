{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40f8cc5",
   "metadata": {},
   "source": [
    "Generate the configuration\n",
    "===\n",
    "0. Install all dependencies (in your venv) with `pip install -e .`\n",
    "1. Set the experiment parameters in the \"Experiment Settings\" section.\n",
    "2. Execute the cell below to overwrite the configuration files.\n",
    "3. run `flwr run . local-sim-gpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a683968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 10 malicious clients out of 100\n",
      "Malicious client IDs: [3, 13, 14, 17, 28, 31, 35, 81, 86, 94]\n",
      "num_gpus:  0.041666666666666664\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "import yaml\n",
    "from attacks.attack_names import AttackNames\n",
    "from detections.detection_names import DetectionNames\n",
    "\n",
    "# --- Experiment Settings ---\n",
    "\n",
    "# Dataset: mnist or cifar10\n",
    "DATASET = \"mnist\"\n",
    "\n",
    "# Number of clients\n",
    "NUM_CLIENTS = 100\n",
    "\n",
    "# Percentage of malicious clients\n",
    "PERCENT_MALICIOUS = 0.1\n",
    "\n",
    "# Number of federation rounds\n",
    "NUM_ROUNDS = 10\n",
    "\n",
    "# Fraction of the clients to choose for training in one round.\n",
    "FRACTION_FIT = 1.0\n",
    "\n",
    "# If true, plots about the loss and accuracy will be generated on wandb\n",
    "# TODO try to use this for all the metrics\n",
    "USE_WANDB = False\n",
    "\n",
    "# Attack method to use\n",
    "ATTACK_METHOD = AttackNames.random_weights_attack\n",
    "\n",
    "# Detection method to use\n",
    "DETECTION_METHOD = DetectionNames.std_dagmm_detection\n",
    "# --- --- --- --- --- --- ---\n",
    "\n",
    "# ========\n",
    "ADDITIONAL_DETECTION_CONFIG = {}\n",
    "if DETECTION_METHOD.value == \"dagmm\":\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"do_data_collection\"] = False   # Set to True to collect training data for the DAGMM model.\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_output_dir\"] = \"./dagmm/dagmm/dagmm_train_data/\" + DATASET + \"/run_15\"  # Output directory of the training data of the current run.\n",
    "\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_threshold_path\"] = \"./dagmm/dagmm/dagmm_anomaly_threshold.yaml\"\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_ignore_up_to\"] = 0   # Does not perform the detection in the first x rounds\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_model_path\"] = \"./dagmm/dagmm/dagmm_model_mnist.pt\"\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_hyperparameters_path\"] = \"./dagmm/dagmm/dagmm_hyperparameters.yaml\"\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"gmm_parameters_paths\"] = {\n",
    "         \"cov\": \"./dagmm/dagmm/gmm_param_cov.pt\",\n",
    "         \"mean\": \"./dagmm/dagmm/gmm_param_mean.pt\",\n",
    "         \"mixture\": \"./dagmm/dagmm/gmm_param_mixture.pt\",\n",
    "    }\n",
    "elif DETECTION_METHOD.value == \"std_dagmm\":\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"do_data_collection\"] = False   # Use DAGMM for performing data collection\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_output_dir\"] = \"-----\" \n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_threshold_path\"] = \"./dagmm/std_dagmm/dagmm_anomaly_threshold.yaml\"\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_ignore_up_to\"] = 0   # Does not perform the detection in the first x rounds\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_model_path\"] = \"./dagmm/std_dagmm/dagmm_model_mnist.pt\"\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"dagmm_hyperparameters_path\"] = \"./dagmm/std_dagmm/dagmm_hyperparameters.yaml\"\n",
    "    ADDITIONAL_DETECTION_CONFIG[\"gmm_parameters_paths\"] = {\n",
    "         \"cov\": \"./dagmm/std_dagmm/gmm_param_cov.pt\",\n",
    "         \"mean\": \"./dagmm/std_dagmm/gmm_param_mean.pt\",\n",
    "         \"mixture\": \"./dagmm/std_dagmm/gmm_param_mixture.pt\",\n",
    "    }\n",
    "# ========\n",
    "\n",
    "num_malicious = max(0, int(NUM_CLIENTS * PERCENT_MALICIOUS))\n",
    "malicious_clients = sorted(random.sample(range(NUM_CLIENTS), num_malicious))\n",
    "\n",
    "print(f\"Selected {num_malicious} malicious clients out of {NUM_CLIENTS}\")\n",
    "print(\"Malicious client IDs:\", malicious_clients) \n",
    "\n",
    "import yaml\n",
    "\n",
    "# Store the dataset to use as a .yaml file\n",
    "with open(\"./config/dataset.yaml\", \"w\") as f:\n",
    "    yaml.dump({\"dataset\": DATASET}, f)\n",
    "\n",
    "# Store the list of malicious clients as a .yaml file\n",
    "with open(\"./config/malicious_clients.yaml\", \"w\") as f:\n",
    "    yaml.dump({\"malicious_clients\": malicious_clients}, f)\n",
    "\n",
    "# Store the attack method as a .yaml file\n",
    "with open(\"./config/attack_method.yaml\", \"w\") as f:\n",
    "     yaml.dump({\"attack_method\": ATTACK_METHOD.value}, f)\n",
    "\n",
    "# Store the detection method as a .yaml file\n",
    "with open(\"./config/detection_method.yaml\", \"w\") as f:\n",
    "    yaml.dump({\"detection_method\": DETECTION_METHOD.value}, f)\n",
    "    if ADDITIONAL_DETECTION_CONFIG:\n",
    "        yaml.dump(ADDITIONAL_DETECTION_CONFIG, f)\n",
    "\n",
    "import toml\n",
    "\n",
    "NUM_CORES = 24  # For 13th Gen Intel(R) Core(TM) i9-13900KF\n",
    "NUM_CPUS = 1\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "NUM_GPUS = 1/NUM_CLIENTS\n",
    "min_gpu_perc = 1/NUM_CORES\n",
    "\n",
    "if NUM_GPUS < min_gpu_perc:\n",
    "    NUM_GPUS = min_gpu_perc\n",
    "    \n",
    "print(\"num_gpus: \", NUM_GPUS)\n",
    "\n",
    "# Load pyproject.toml\n",
    "with open(\"pyproject.toml\", \"r\") as f:\n",
    "    data = toml.load(f)\n",
    "\n",
    "# Modify the values\n",
    "data[\"tool\"][\"flwr\"][\"app\"][\"config\"][\"num-server-rounds\"] = NUM_ROUNDS\n",
    "data[\"tool\"][\"flwr\"][\"app\"][\"config\"][\"fraction-fit\"] = FRACTION_FIT\n",
    "data[\"tool\"][\"flwr\"][\"app\"][\"config\"][\"use-wandb\"] = USE_WANDB\n",
    "\n",
    "data[\"tool\"][\"flwr\"][\"federations\"][\"local-sim\"][\"options\"][\"num-supernodes\"] = NUM_CLIENTS\n",
    "data[\"tool\"][\"flwr\"][\"federations\"][\"local-sim-gpu\"][\"options\"][\"num-supernodes\"] = NUM_CLIENTS\n",
    "data[\"tool\"][\"flwr\"][\"federations\"][\"local-sim-gpu\"][\"options\"][\"backend\"][\"client-resources\"][\"num-cpus\"] = NUM_CPUS\n",
    "data[\"tool\"][\"flwr\"][\"federations\"][\"local-sim-gpu\"][\"options\"][\"backend\"][\"client-resources\"][\"num-gpus\"] = NUM_GPUS\n",
    "\n",
    "# Save changes back to pyproject.toml\n",
    "with open(\"pyproject.toml\", \"w\") as f:\n",
    "    toml.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
